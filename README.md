ğŸ§  Console Chatbot com Semantic Kernel + Ollama

Projeto em .NET usando Semantic Kernel com o provedor local Ollama, permitindo conversar com modelos como Llama 3.1 diretamente no terminal.

ğŸš€ Tecnologias usadas
.NET 9
Semantic Kernel (Microsoft.SemanticKernel)
Ollama como provedor de LLM local
C#
Console Application
Logging com ConsoleLogger

ğŸ“Œ PrÃ©-requisitos
1. Instalar o Ollama

Baixe e instale em:
https://ollama.com/download

2. Baixar o modelo que deseja usar

Exemplo com Llama 3.1:
ollama pull llama3.1
Ou o que vocÃª preferir, como mistral, phi3, etc.

3. Pacotes NuGet necessÃ¡rios
dotnet add package Microsoft.SemanticKernel
dotnet add package Microsoft.SemanticKernel.Connectors.Ollama

â–¶ï¸ Rodando o projeto

Clone o repositÃ³rio
Instale os pacotes
Garanta que o Ollama estÃ¡ rodando (ollama serve)

Execute:
dotnet run

ğŸ’¬ Como funciona o chatbot

O app inicia um loop no console
VocÃª digita uma mensagem
A mensagem entra no histÃ³rico (ChatHistory)
O Semantic Kernel envia tudo para o modelo Ollama
A resposta Ã© mostrada na tela
O histÃ³rico Ã© atualizado e a conversa continua
